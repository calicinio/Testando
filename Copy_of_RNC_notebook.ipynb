{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of RNC_notebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/calicinio/Testando/blob/master/Copy_of_RNC_notebook.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Y5-vHrI9l0A7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Notebook: Rede Neural Convolucional \n",
        "### EEE901 - Introdução a Inteligência Computacional 2018/1\n",
        "###Grupo:\n",
        "\n",
        "* Alan Souza\n",
        "* Alex Assis\n",
        "* Douglas Marques\n",
        "* Roger Ferreira\n",
        "\n",
        "email para envio: _redeneuralconvolucional@gmail.com_"
      ]
    },
    {
      "metadata": {
        "id": "IpmfIOBtUBLj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##*Redes Neurais Convolucionais (Convolutional Neural Networks - CNN)*\n",
        "\n",
        "As redes neurais convolucionais (RNC) são redes neurais que usam a convolução no lugar da simples multiplicação de matrizes em pelo menos uma de suas camadas. As RNCs são especializadas em processamento de dados que possuem uma topologia em grade, como dados de séries temporais (grade 1D) e dados de imagem (grade 2D).\n",
        "\n",
        "A convolução é uma operação entre duas funções, definida como: a integral do produto de uma das funções, por uma cópia deslocada e invertida da outra:\n",
        "\n",
        "$$s(t)=(f*g)(t)= ∫_{-∞}^{∞}f(τ)g(t-τ)dτ.$$\n",
        "\n",
        "O passo a passo de como a convolução é realizada pode ser visto na animação do link: [ANIMAÇÃO DA CONVOLUÇÃO](https://www.youtube.com/watch?annotation_id=annotation_4270354579&feature=iv&src_vid=C1N55M1VD2o&v=jwlfSIBNqP8)\n",
        "\n",
        "Contudo, quando trabalhamos com processamento digital, usualmente as funções (ou dados)  são discretas. Neste caso, é usada a convolução discreta:\n",
        "\n",
        "$$s(i)=(f*g)(i)= ∑_{-∞}^{∞}f(τ)g(i-τ).$$\n",
        "\n",
        "Na terminologia de redes convolucionais, o primeiro argumento (f) da convolução é frequentemente referido como **entrada**, e o segundo (g) como **kernel**. A saída (s) é, às vezes, referenciada como **mapa de características**.\n",
        "\n",
        "Para o caso em que a entrada, por exemplo, é uma imagem, o kernel tem duas dimensões:\n",
        "\n",
        "$$S(i,j)=(I*K)(i,j)= ∑_{m}∑_{n}I(m,n)K(i-m)(j-n).$$\n",
        "\n",
        "[Goodfellow; Bengio; Courville, 2016]"
      ]
    },
    {
      "metadata": {
        "id": "igmFwMIDSuw7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Camadas das Redes Neurais Convolucionais**\n",
        "\n",
        "###Camada convolutiva \n",
        "A Camada convolutiva  é formada por um conjunto de filtros ou <i> kernels </i> que são ajustados na etapa de treinamento da rede. Os filtros são matrizes pequenas, por exemplo, (5 x 5 x 3) compostas por valores reais que podem ser interpretados como pesos. Esses filtros são convoluídos com os dados de entrada para obter um mapa de características. Na Figura 1, temos a convolução entre imagem (3 x 3 x 3) e um filtro (2 x 2 x 3), na operação não é realizada a inversão do kernel. A convolução é dada pelo produto escalar. [Pacheco, 2018]\n",
        "<center>\n",
        "    </figure>\n",
        "<img src=\"http://www.computacaointeligente.com.br/wp-content/uploads/2017/07/conv.jpg\" width=400 height=400> \n",
        "<figcaption>Figura 1. - Convolução.</figcaption>\n",
        "    </figure>\n",
        "</center>\n",
        "\n",
        "Os _kernels_ dão maior robustez ao modelo, eles são capazes de lidar com as variações de distorção, rotação e translação na imagem de entrada<sup> 1</sup>, além de reduzir o número de parâmetros livres a serem otimizados, devido ao compartilhamento dos pesos, em comparação com uma rede totalmente conectada. Uma vez extraída a característica (mapa de características), sua localização na imagem é menos importante, desde que sua posição relativa a outras características próximas seja preservada. Na Figura 2, não é tão importante saber a região onde o cachorro está para reconhecê-lo, mas sim que partes que compõem o animal, (olhos, boca, nariz) estejam organizadas e sejam conhecidas. [Haykin, 2008]\n",
        " <center>\n",
        "  <figure>\n",
        "  <img src=\"https://t2.uc.ltmcdn.com/pt/images/6/7/1/img_por_que_os_cachorros_fogem_23176_600.jpg\" width=200 height=170 />\n",
        "    <figcaption>Figura 2 - Cachorro.</figcaption>\n",
        "  </figure>\n",
        "  </center>\n",
        "\n",
        "###Camada de _pooling_ (subamostragem)\n",
        " Na camada de _pooling_, é realizada a redução do tamanho espacial das matrizes resultantes da convolução. Consequentemente, essa técnica reduz a quantidade de parâmetros a serem aprendidos na rede, contribuindo para o controle de _overfitting_. Na Figura 3, temos o _max pooling_<sup>2</sup> de uma matriz de convolução 4 x 4 x 3. O filtro do _pooling_ abrange regiões 2 x 2 em cada canal, com _stride_ = 2. [Pacheco, 2018]\n",
        " <center>\n",
        "    <figure>\n",
        "  <img src=\"http://www.computacaointeligente.com.br/wp-content/uploads/2017/07/pooling.jpg\" width=250 height=160 />\n",
        "  <figcaption>Figura 3. - Max Pooling.</figcaption>\n",
        "    </figure>\n",
        "  </center>\n",
        "\n",
        "###Camada completamente conectada\n",
        "A camada é completamente conectada com a camada anterior e normalmente são utilizadas como última camada da rede neural convolucional. Aceita as mesmas técnicas para melhorar o desempenho de uma rede neural artificial. Na Figura 4, temos a conexão de uma camada convolucional com uma camada totalmente conectada, onde 48 mapas de características (4 x 4) são colocados de forma linear formando 768 entradas para camada totalmente conectada, que por sua vez, possui 500 neurônios ocultos que resultam em 10 saídas para rede. [Pacheco, 2018]\n",
        " <center>\n",
        "  <figure>\n",
        "  <img src=\"http://www.computacaointeligente.com.br/wp-content/uploads/2017/07/fc.jpg\" width=350 height=180 title=\"Camada totalmente conectada\" />\n",
        "  <figcaption>Figura 4 - Arquitetura da camada completamente conectada.</figcaption>\n",
        "  </figure>\n",
        "  </center>\n",
        " \n",
        "Na Figura 5, é apresentada a arquitetura de rede covolucional **LeNet-5**, na qual podemos ver as camadas citadas anteriormente. Ela foi desenvolvida por [LeCun et al. , 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf) e foi a primeira aplicação de CNN que obteve sucesso. Foi utilizada para classificar dígitos, por conta disso, muito utilizada em tarefas como a leitura de códigos postais.  [Pacheco, 2018]\n",
        "<center>\n",
        "  <figure>\n",
        "  <img src=\"http://www.computacaointeligente.com.br/wp-content/uploads/2017/07/lenet.png\" width=500 height=180 title=\"Arquitetura LeNet-5\"/>\n",
        "  <figcaption>Figura 5 - LeNet-5 Arquitetura.</figcaption>\n",
        "    <f/igure>\n",
        "  </center>\n",
        "\n",
        "Este tópico é muito extenso e não foi possivel cobrir todos os aspectos relacionados a CNN, para quem deseja se aprofundar mais no assunto recomendamos: [http://www.deeplearningbook.org/] \n",
        "\n",
        "[Jianxin Wu, 2017, Introduction to Convolutional Neural Networks](https://pdfs.semanticscholar.org/450c/a19932fcef1ca6d0442cbf52fec38fb9d1e5.pdf)\n",
        "\n",
        "Notas: <br>\n",
        "<sup>1</sup> - Uma técnica chamada <i> Data Augmentation</i>, pode ser utilizada para que essas propriedades sejam aprendidas por redes CNN em situações com poucos dados de treinamento, ver link [Data Augmentation ](https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced)\n",
        "\n",
        "<sup>2</sup> Outros exemplos de <i>Pooling</i> são: <i>average pooling</i> e <i>L2 pooling</i> utilizados para obtenção de diferentes propriedades.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "6og3S3HuInvu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Inicialmente vamos passar um exemplo passo a passo para demonstrar a criação de uma CNN para o dataset MNIST."
      ]
    },
    {
      "metadata": {
        "id": "FxKnMxZm44Hp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "59e7f267-1f8f-49a8-a20e-0c047a38af17"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "xdeIH3deKvjc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos importar os dados com a função <b> load_data</b> de forma que possamos obter algumas características dos mesmos.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ACio47_mKvvC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "0a1ad6a4-3780-469a-d3f6-93765483b533"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print(\"Tamanho x_train: \", x_train.shape)\n",
        "print(\"Tamanho x_test: \",x_test.shape)\n",
        "print (\"Classe dos elementos que compoem a matriz: \", type(x_train[1,1,1]) )\n",
        "plt.axis('off')\n",
        "plt.imshow(x_train[1])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamanho x_train:  (60000, 28, 28)\n",
            "Tamanho x_test:  (10000, 28, 28)\n",
            "Classe dos elementos que compoem a matriz:  <class 'numpy.uint8'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f64849384a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQLAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f64e618fac8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sDSkHOcFLOx1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Uma das imagens para visualizar o conjunto de treinamento foi exibida, digito 0. Podemos observar que os dados de entrada são compostos por imagens preto e branco (28px28p), com uma resolução de 8 bits, ou seja 0-255. Temos 60000 dígitos no conjunto de treinamento e 10000 no conjunto de teste. "
      ]
    },
    {
      "metadata": {
        "id": "IK12yvddPgBT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Na próxima etapa precisamos converter os valores de y_test e y_train de inteiro para uma matriz de categorias. Por exemplo, o valor 3, deve ser convertido para  [0 0 0 1 0 ... 0] . Utilize a função  <b>keras.utils.to_categorical (data, numero_de_classes)</b>, para fazer a conversão. Obs: Os valores de  saída são os algoritmos de 0 até 9."
      ]
    },
    {
      "metadata": {
        "id": "gEM90_QaOK_n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# converte os dados para uma matrix\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test =  keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Adiciona aos dados uma dimensao, representando o canal, neste caso 1 (preto e branco)\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rNdtpzp1SOC0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Precisamos agora escalonar os dados de entrada entre 0 e 1. Para isso, note que os dados estão como <i>uint8</i>, conforme observado anteriormente."
      ]
    },
    {
      "metadata": {
        "id": "oBb8m3kaSOQs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255\n",
        "\n",
        "\n",
        "print (\"Matriz do elemento 0: \", x_train[1,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ENTdXFaCYFvI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A construção do modelo da rede  com o Keras se dar por base da adição de camadas ou <i>Layers</i>. Inicialmente definimos o modelo como sendo sequencial."
      ]
    },
    {
      "metadata": {
        "id": "cAj2uM7RYl42",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i6jI4_1YXwZb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos acrescentar o primeiro <i>layer</i> com uma camada convolucional, definimos 16 canais de saída, um kernel de tamanho (3x3) e função de ativação REctified Linear Unit - 'ReLU', existe muita discussão com relação a funções de ativação em CNNs, mas parece haver certo consenso de que ReLU tem uma boa performance em [Deep Neural Networks](<http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf>).  "
      ]
    },
    {
      "metadata": {
        "id": "SpgNZu7aZD5Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu',input_shape=[28,28,1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vdSwQTJgZMP2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adicione mais um <i> layer</i> com outra camada convolucional com 32 canais de saída, kernel (3,3) e função de ativação ''relu'.  Não é  necessário incluir o formato da entrada nesse <i>layer</i> ."
      ]
    },
    {
      "metadata": {
        "id": "0vB1kn3hdQeb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu' ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zHRik4wcenj-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos adicionar uma camada <i>Max Pooling</i> com uma janela de (2x2)."
      ]
    },
    {
      "metadata": {
        "id": "2EsA75bYenxz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(MaxPooling2D(pool_size=(2, 2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a3bDfJPCfN5i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Depois de passar pela segunda camada de convolução vamos abrir a rede, comando <i>Flatten</i>, e inserir uma camada totalmente conectada <i>Dense</i>. Pesquise sobre a utilização do <i>Dropout</i> em redes neurais e de uma breve explicação sobre as vantagens de se utilizar o <i>Dropout</i>.Retire o comentário da linha se desejar."
      ]
    },
    {
      "metadata": {
        "id": "03r1_pfQfFLT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9B0gqpK8gMWx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dropout : é uma técnica utilizada para descartar alguns neurônios com vistas a evitar overfit.\n"
      ]
    },
    {
      "metadata": {
        "id": "ju6b1GKggMed",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finalize nossa rede neural com uma camada <i>Dense</i>, com o número de neurônios, igual ao número de classes, dígitos de [0 ,9], e função de ativação 'softmax'."
      ]
    },
    {
      "metadata": {
        "id": "r5xxYXrmgXud",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kJVNoBXAiB_B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Precisamos compilar nossa rede neural definindo: a função de custo, neste caso <i>cross entropy</i>, o algoritmo de otimização e a métrica de avaliação para depois treinarmos nosso modelo. A função <b>.fit</b> faz o treinamento da RNC, veja a documentação do Keras para entender seus parâmetros <https://keras.rstudio.com/reference/fit.html>"
      ]
    },
    {
      "metadata": {
        "id": "Rnf2dPt7ilxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "b94c2689-0184-47c1-cb11-8437c6ae4676"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                294976    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 300,426\n",
            "Trainable params: 300,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QcSc9Jz8x3c6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Podemos ver como a rede ficou com sua arquitetura final (comando <b> model.summary() </b>)"
      ]
    },
    {
      "metadata": {
        "id": "Va4Mxszsxxbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "78ecf260-f4a2-4259-cf9e-5bcf005908e8"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=1,\n",
        "          epochs=1,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            " 4661/60000 [=>............................] - ETA: 7:42 - loss: 0.7211 - acc: 0.7698"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "59994/60000 [============================>.] - ETA: 0s - loss: 0.2688 - acc: 0.9255"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60000/60000 [==============================] - 502s 8ms/step - loss: 0.2689 - acc: 0.9255 - val_loss: 0.0910 - val_acc: 0.9747\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6483e59400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "BlKmDoa7jplC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finalmente exibimos os valores finais das métricas após o treinamento."
      ]
    },
    {
      "metadata": {
        "id": "0lpDAUGrjpw8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ba8a0697-6a35-49ea-bffa-8f477953ac29"
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Função custo: ', score[0])\n",
        "print('Acurácia: ', score[1])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Função custo:  0.09100105223404244\n",
            "Acurácia:  0.9747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o8LM-h2IFhEU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A execução do algoritmo demora, por isso, foram colocados valores 1 para os parâmetros da função fit, você pode aumentar esses valores para obter uma melhor acurácia.  "
      ]
    },
    {
      "metadata": {
        "id": "eOcmLB1a1zDl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ## EXTRA: Outras Arquiteturas de Redes Neurais Convolutivas\n",
        " \n",
        " * **AlexNet**\n",
        "\n",
        "A arquitetura AlexNet foi o trabalho que popularizou as CNNs para visão computacional. Proposta por Krizhevsky et al. [krizhevsky, 2012], foi a metodologia vencedora do desafio ImageNet em 2012. Sua arquitetura é bastante similar à da LeNet-5, porém ela é mais profunda, com mais camadas convolucionais, e possui muito mais mapas de característica.  [Pacheco, 2018]\n",
        "\n",
        "<center>\n",
        "  <img src=\"http://www.computacaointeligente.com.br/wp-content/uploads/2017/07/alexnet.png\" width=500 height=250 title=\"Arquitetura AlexNet\"/>\n",
        "  </center>\n",
        " \n",
        " * **VGGNet**\n",
        "\n",
        "A arquitetura VGGNet foi proposta por Simonyan e Zisserman [Simonyan, 2014] e teve como principal contribuição mostrar que a profundidade da rede é um componente crítico para uma boa performance. O modelo padrão da VGGNet possui diversas camadas de convolução aplicando filtros 3 x 3 x 3 e _max pooling_ com filtros 2 x 2 x 3. [Pacheco, 2018]\n",
        "\n",
        "<center>\n",
        "  <img src=\"http://www.computacaointeligente.com.br/wp-content/uploads/2017/07/vggnet.png\" width=500 height=250 title=\"Arquitetura AlexNet\"/>\n",
        "  </center>"
      ]
    },
    {
      "metadata": {
        "id": "IvyeLlRo1zQK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Bibliografia\n",
        "\n",
        "Goodfellow, I.; Bengio, Y. ; Courville, A. **Deep Learning**. MIT Press, 2016. Disponível em: <http://www.deeplearningbook.org>\n",
        "\n",
        "Krizhevsky, A.; Sutskever, I.; and Hinton, G. E.  **Imagenet classification with deep convolutional neural networks,** in Advances in neural information processing systems, 2012, pp. 1097–1105.\n",
        "\n",
        "LeCun, Y.;  Bottou, L.; Bengio, Y.; and Haffner, P. , **Gradient-based learning applied to document recognition,** Proceedings of the IEEE, vol. 86, no. 11, pp. 2278–2324, 1998.\n",
        "\n",
        "Pacheco, A.  **Redes Neurais Convolutivas - CNN**  Disponível em: <http://www.computacaointeligente.com.br/artigos/redes-neurais-convolutivas-cnn/> Acessado em: 30 de maio de 2018.\n",
        "\n",
        "Simon, Haykin, **Neural Networks and Learning Machines** 3rd edition, Pretice Hall, 2008.\n",
        "\n",
        "Simonyan, K.  and Zisserman, A.  **Very deep convolutional networks for large-scale image recognition** arXiv preprint arXiv:1409.1556, 2014.\n",
        "\n",
        "Site: <http://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/> acessado em 01 de junho de 2018\n",
        "\n",
        "Site: <https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py> acessado em 01 de junho de 2018\n",
        "\n",
        "Site: <https://keras.rstudio.com/index.html> acessado em 01 de junho de 2018\n",
        "\n",
        "Wu, Jianxin. [\"Introduction to convolutional neural networks.\"](https://pdfs.semanticscholar.org/450c/a19932fcef1ca6d0442cbf52fec38fb9d1e5.pdf) National Key Lab for Novel Software Technology. Nanjing University. China (2017)."
      ]
    }
  ]
}